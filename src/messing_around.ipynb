{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lgKOjFp_J0u4"
      },
      "source": [
        "# Messing Around - Experiments and other Shenanigans"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XOl0taUdJ0u8"
      },
      "source": [
        "## Reproducing the _Spread_ metric introduced by Zhao at al. (2022)\n",
        "\n",
        "I know they're using the model _SimCSE with RoBERTa-large base_ which is just\n",
        "available on GitHub and Huggingface Transformers. The most annoying thing right\n",
        "now is to determine what is meant with the following sentence:\n",
        "\n",
        "> For some input $z = (x, y) \\in D$, let $f(z)$ denote the vector valued\n",
        "> features of the input x produced by the model.\n",
        "\n",
        "What are the _vector-valued features_? Currently, I think these represent the\n",
        "`embeddings` as used in the following code snippet given in the [example\n",
        "tutorial](https://github.com/princeton-nlp/SimCSE) of the SimCSE BERT model:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dxiztY5XJ0u_",
        "outputId": "72e36850-2ad6-4e15-e72c-6dee830672f4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Cosine similarity between \"There's a kid on a skateboard.\" and \"A child is skateboarding.\" is: 0.933\n",
            "Cosine similarity between \"There's a kid on a skateboard.\" and \"A child resides inside the house.\" is: 0.367\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "from scipy.spatial.distance import cosine\n",
        "from transformers import AutoModel, AutoTokenizer\n",
        "\n",
        "# Import our models. The package will take care of downloading the models automatically\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"princeton-nlp/sup-simcse-bert-base-uncased\")\n",
        "model = AutoModel.from_pretrained(\"princeton-nlp/sup-simcse-bert-base-uncased\")\n",
        "\n",
        "# Tokenize input texts\n",
        "texts = [\n",
        "    \"There's a kid on a skateboard.\",\n",
        "    \"A child is skateboarding.\",\n",
        "    \"A child resides inside the house.\"\n",
        "]\n",
        "inputs = tokenizer(texts, padding=True, truncation=True, return_tensors=\"pt\")\n",
        "\n",
        "# Get the embeddings\n",
        "with torch.no_grad():\n",
        "    embeddings = model(**inputs, output_hidden_states=True, return_dict=True).pooler_output\n",
        "\n",
        "# Calculate cosine similarities\n",
        "# Cosine similarities are in [-1, 1]. Higher means more similar\n",
        "cosine_sim_0_1 = 1 - cosine(embeddings[0], embeddings[1])\n",
        "cosine_sim_0_2 = 1 - cosine(embeddings[0], embeddings[2])\n",
        "\n",
        "print(\"Cosine similarity between \\\"%s\\\" and \\\"%s\\\" is: %.3f\" % (texts[0], texts[1], cosine_sim_0_1))\n",
        "print(\"Cosine similarity between \\\"%s\\\" and \\\"%s\\\" is: %.3f\" % (texts[0], texts[2], cosine_sim_0_2))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sTrXk1BKJ0vC"
      },
      "source": [
        "The `pooler_output` seems to refer to the value of the classification token, `[CLS]`, in\n",
        "the BERT-type model. I wasn't sure why this output is particularly important\n",
        "because it resides as the beginning of the sentence, but given that bert is an\n",
        "_encoder only_ network this makes sense now: while typical _decoder only_\n",
        "transformers only look back, encoders look back as well as ahead. The final\n",
        "result of the classification task of the BERT model thus resides in the first\n",
        "token before the classified sentence, the `[CLS]` token."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6YSxh_3EJ0vD"
      },
      "source": [
        "If it is the case that these values are used instead of the tokenizer embeddings\n",
        "as I first thought, that means the method is more specific to this particular\n",
        "model architecture than I would like. Still, in the [`transformers`\n",
        "documentation](https://huggingface.co/docs/transformers/main_classes/output#transformers.modeling_outputs.BaseModelOutputWithPooling.pooler_output)\n",
        "it seems like this is not only a feature of BERT models, so it should probably\n",
        "be fine. I do need to try this out with a different model type tho."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P6F46GC3J0vE"
      },
      "source": [
        "After fiddling for a bit, I've concluded the following. While the\n",
        "`pooler_output` is not unique to BERT models, it does not seem like the value\n",
        "necessary for the distance in the paper. It is a single vector while they are\n",
        "talking about multiple features, each of which is a vector. Therefore, we expect\n",
        "to take some matrix norm (since the output of $f(z)$ would then be a matrix).\n",
        "Here is my attempt at reconstructing the method they seem to have used in the\n",
        "paper."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZO6QvyOPJ0vH",
        "outputId": "2b8135ef-4104-4af2-e7c9-e84c60d58f8c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Distance between \"There's a kid on a skateboard.\" and \"A child is skateboarding.\" is: 4.552\n",
            "Distance between \"There's a kid on a skateboard.\" and \"A child resides inside the house.\" is: 3.318\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "from scipy.spatial.distance import cosine\n",
        "from transformers import AutoModel, AutoTokenizer\n",
        "\n",
        "# Import our models. The package will take care of downloading the models\n",
        "# automatically. NOTE: don't use seq2seq.. they're really annoying.\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"sshleifer/tiny-gpt2\")\n",
        "model = AutoModel.from_pretrained(\"sshleifer/tiny-gpt2\")\n",
        "\n",
        "# Tokenize input texts\n",
        "texts = [\n",
        "    \"There's a kid on a skateboard.\",\n",
        "    \"A child is skateboarding.\",\n",
        "    \"A child resides inside the house.\"\n",
        "]\n",
        "tokenizer.pad_token = \" \" # NOTE: I don't know whether this is legit\n",
        "inputs = tokenizer(texts, padding=True, truncation=True, return_tensors=\"pt\")\n",
        "\n",
        "# Get the embeddings\n",
        "with torch.no_grad():\n",
        "    embeddings: torch.Tensor = model(**inputs, output_hidden_states=True, return_dict=True).last_hidden_state\n",
        "\n",
        "# Calculate distance as defined in the paper\n",
        "distance_0_1 = (embeddings[0] - embeddings[1]).norm()\n",
        "distance_0_2 = (embeddings[0] - embeddings[2]).norm()\n",
        "\n",
        "print(\"Distance between \\\"%s\\\" and \\\"%s\\\" is: %.3f\" % (texts[0], texts[1], distance_0_1))\n",
        "print(\"Distance between \\\"%s\\\" and \\\"%s\\\" is: %.3f\" % (texts[0], texts[2], distance_0_2))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-yeylzHnJ0vI"
      },
      "source": [
        "While this is not an equivalent to the method shown before (no cosine\n",
        "similarity), this seems like a reasonable substitute for it and I don't find it\n",
        "unreasonable to imageine that the authors would have gone through similar steps."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5OyfwnyHJ0vJ"
      },
      "source": [
        "### Detour: Token Embeddings\n",
        "\n",
        "One thing I am curious about to see how much the upper method compares to simply\n",
        "using the embeddings generated by the tokenizer. Let's see!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o2m5vI53J0vM",
        "outputId": "1268bb0a-4f94-4128-b480-e5ec81123e95"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Distance between \"There's a kid on a skateboard.\" and \"A child is skateboarding.\" is: 80844.202\n",
            "Distance between \"There's a kid on a skateboard.\" and \"A child resides inside the house.\" is: 77876.963\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "from scipy.spatial.distance import cosine\n",
        "from transformers import AutoModel, AutoTokenizer\n",
        "\n",
        "# Import our models. The package will take care of downloading the models\n",
        "# automatically. NOTE: don't use seq2seq.. they're really annoying.\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"sshleifer/tiny-gpt2\")\n",
        "model = AutoModel.from_pretrained(\"sshleifer/tiny-gpt2\")\n",
        "\n",
        "# Tokenize input texts\n",
        "texts = [\n",
        "    \"There's a kid on a skateboard.\",\n",
        "    \"A child is skateboarding.\",\n",
        "    \"A child resides inside the house.\"\n",
        "]\n",
        "tokenizer.pad_token = \" \" # NOTE: I don't know whether this is legit\n",
        "inputs = tokenizer(texts, padding=True, truncation=True, return_tensors=\"pt\").input_ids\n",
        "\n",
        "# Calculate distance as defined in the paper\n",
        "distance_0_1 = (inputs[0] - inputs[1]).double().norm()\n",
        "distance_0_2 = (inputs[0] - inputs[2]).double().norm()\n",
        "\n",
        "print(\"Distance between \\\"%s\\\" and \\\"%s\\\" is: %.3f\" % (texts[0], texts[1], distance_0_1))\n",
        "print(\"Distance between \\\"%s\\\" and \\\"%s\\\" is: %.3f\" % (texts[0], texts[2], distance_0_2))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7ktmXrtHJ0vO"
      },
      "source": [
        "Ah yes, no, absolutely not..."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eOFhlyCIJ0vP"
      },
      "source": [
        "### Detour: Padding Matters\n",
        "\n",
        "One thing I do notice is that, when considering the distance, the padding used\n",
        "to make a single batch matters quite a bit. I guess this wasn't an issue before,\n",
        "but the `tiny-gpt` model doesn't have a built-in padding token. I can iterate\n",
        "over all the different ascii characters and see what their impact is on the distance."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1mjCA_2eJ0vQ",
        "outputId": "deff8f92-9133-4a52-c4e2-b53b1cda86b0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Spread in difference between two sentences: \n",
            "  1. \"There's a kid on a skateboard.\"\n",
            "  2. \"A child is skateboarding.\"\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "def get_diff_with_padding(padding=\" \"):\n",
        "    tokenizer.pad_token = padding\n",
        "    inputs = tokenizer(texts, padding=True, truncation=True, return_tensors=\"pt\")\n",
        "\n",
        "    with torch.no_grad():\n",
        "        embeddings: torch.Tensor = model(**inputs, output_hidden_states=True, return_dict=True).last_hidden_state\n",
        "\n",
        "    # Calculate distance as defined in the paper\n",
        "    distance_0_1 = (embeddings[0] - embeddings[1]).norm().item()\n",
        "    distance_0_2 = (embeddings[0] - embeddings[2]).norm().item()\n",
        "\n",
        "    return abs(distance_0_1 - distance_0_2)\n",
        "\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import string\n",
        "\n",
        "results = pd.DataFrame({ \"char\" : list(string.printable) })\n",
        "results.insert(0, column=\"diff\", value=results[\"char\"].map(get_diff_with_padding))\n",
        "results = results.sort_values(by=\"diff\")\n",
        "\n",
        "_ = sns.boxplot(results, y=\"diff\")\n",
        "\n",
        "print(f\"Spread in difference between two sentences: \\n  1. \\\"{texts[0]}\\\"\\n  2. \\\"{texts[1]}\\\"\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PRyxvQ7QJ0vR"
      },
      "source": [
        "Given that the average distance of these two sentences are around 1.2, a spread\n",
        "of .5 does not seem insignificant. Does this matter? Maybe not, but it is\n",
        "strange. If I would like this to be compatible with various models I should\n",
        "first figure out how this is generally dealt with."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "alUscasiJ0vS"
      },
      "source": [
        "### Reflection\n",
        "\n",
        "Now that we effectively have the _Spread_ measure (calculating it fully should\n",
        "not be a problem as we now have all the puzzle pieces), what is the next step?\n",
        "We could do a couple of things:\n",
        "\n",
        "- Compare this measure with that of the **HardenedMetaSet++** technique.\n",
        "- Show whether this has any value in terms of security\n",
        "- Continue working on reproducing the paper\n",
        "\n",
        "While I'm not sure which would be the most effective to work on, I think the\n",
        "second is the most important to the thesis itself. I'm aware of some stuff in\n",
        "the current paper that might be reason for concern, but I will let those be for\n",
        "now. Let's, for now, assume that the current measure is the end-all and be-all\n",
        "of few-shot dataset hardness."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mugccEooJ0vS"
      },
      "source": [
        "## Working with GPTFuzzer by Yu et al. (2023)\n",
        "\n",
        "To that end, I would like to be able to run my own test using the method used in\n",
        "_GPTFuzzer_. The reason for this tool specifically, is because it generated new\n",
        "samples from old ones, specifically attacking the adaptability we are trying to\n",
        "establish. The tool seems really easy to work with and is fully available on\n",
        "github. It's slightly annoying that it's not available as a package, but this is\n",
        "my current workaround, maybe I'll submit a PR that makes it easier to interact\n",
        "with other code.\n",
        "\n",
        "I switched over to using conda environments because the paper uses this, and I\n",
        "think it's a good idea given the amount of packages I'll have to deal with.\n",
        "Furthermore, I'm working in a `devcontainer` which means that not all kernel\n",
        "features are (readily) available, so too for my NVidia GPU. I've followed [this\n",
        "stackoverflow\n",
        "thread](https://stackoverflow.com/questions/72129213/using-gpu-in-vs-code-container)\n",
        "to fix this."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Set up python dependencies and environment"
      ],
      "metadata": {
        "id": "_xYPdbkzb4bx"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zjU8vsXaJ0vU",
        "outputId": "1a5bf401-96f4-4483-c0bf-70cd9d83527e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting package metadata (current_repodata.json): - \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ WARNING conda.models.version:get_matcher(546): Using .* with relational operator is superfluous and deprecated and will be removed in a future version of conda. Your spec was 1.7.1.*, but conda is ignoring the .* and treating it as 1.7.1\n",
            "\b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\bdone\n",
            "Solving environment: - \b\bfailed with initial frozen solve. Retrying with flexible solve.\n",
            "Collecting package metadata (repodata.json): | \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ WARNING conda.models.version:get_matcher(546): Using .* with relational operator is superfluous and deprecated and will be removed in a future version of conda. Your spec was 1.6.0.*, but conda is ignoring the .* and treating it as 1.6.0\n",
            "WARNING conda.models.version:get_matcher(546): Using .* with relational operator is superfluous and deprecated and will be removed in a future version of conda. Your spec was 1.9.0.*, but conda is ignoring the .* and treating it as 1.9.0\n",
            "WARNING conda.models.version:get_matcher(546): Using .* with relational operator is superfluous and deprecated and will be removed in a future version of conda. Your spec was 1.8.0.*, but conda is ignoring the .* and treating it as 1.8.0\n",
            "\b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\bdone\n",
            "Solving environment: \\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ WARNING conda.core.solve:_add_specs(639): pinned spec python=3.10 conflicts with explicit specs.  Overriding pinned spec.\n",
            "\b\b| \b\bfailed with initial frozen solve. Retrying with flexible solve.\n",
            "\n",
            "PackagesNotFoundError: The following packages are missing from the target environment:\n",
            "  - cudatoolkit=12.2\n",
            "\n",
            "\n",
            "Requirement already satisfied: fschat in /usr/local/lib/python3.10/site-packages (0.2.35)\n",
            "Requirement already satisfied: vllm in /usr/local/lib/python3.10/site-packages (0.2.7)\n",
            "Requirement already satisfied: openai in /usr/local/lib/python3.10/site-packages (1.9.0)\n",
            "Requirement already satisfied: termcolor in /usr/local/lib/python3.10/site-packages (2.4.0)\n",
            "Requirement already satisfied: openpyxl in /usr/local/lib/python3.10/site-packages (3.1.2)\n",
            "Requirement already satisfied: google-generativeai in /usr/local/lib/python3.10/site-packages (0.3.2)\n",
            "Requirement already satisfied: anthropic in /usr/local/lib/python3.10/site-packages (0.10.0)\n",
            "Requirement already satisfied: accelerate in /usr/local/lib/python3.10/site-packages (0.26.1)\n",
            "Requirement already satisfied: chardet in /usr/local/lib/python3.10/site-packages (5.2.0)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/site-packages (2.2.0)\n",
            "Requirement already satisfied: ipython in /usr/local/lib/python3.10/site-packages (8.20.0)\n",
            "Requirement already satisfied: shortuuid in /usr/local/lib/python3.10/site-packages (from fschat) (1.0.11)\n",
            "Requirement already satisfied: nh3 in /usr/local/lib/python3.10/site-packages (from fschat) (0.2.15)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/site-packages (from fschat) (3.9.1)\n",
            "Requirement already satisfied: rich>=10.0.0 in /usr/local/lib/python3.10/site-packages (from fschat) (13.7.0)\n",
            "Requirement already satisfied: prompt-toolkit>=3.0.0 in /usr/local/lib/python3.10/site-packages (from fschat) (3.0.43)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/site-packages (from fschat) (1.26.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/site-packages (from fschat) (2.28.2)\n",
            "Requirement already satisfied: fastapi in /usr/local/lib/python3.10/site-packages (from fschat) (0.109.0)\n",
            "Requirement already satisfied: httpx in /usr/local/lib/python3.10/site-packages (from fschat) (0.26.0)\n",
            "Requirement already satisfied: tiktoken in /usr/local/lib/python3.10/site-packages (from fschat) (0.5.2)\n",
            "Requirement already satisfied: uvicorn in /usr/local/lib/python3.10/site-packages (from fschat) (0.26.0)\n",
            "Requirement already satisfied: pydantic<2,>=1 in /usr/local/lib/python3.10/site-packages (from fschat) (1.10.13)\n",
            "Requirement already satisfied: markdown2[all] in /usr/local/lib/python3.10/site-packages (from fschat) (2.4.12)\n",
            "Requirement already satisfied: ninja in /usr/local/lib/python3.10/site-packages (from vllm) (1.11.1.1)\n",
            "Requirement already satisfied: ray>=2.5.1 in /usr/local/lib/python3.10/site-packages (from vllm) (2.9.1)\n",
            "Requirement already satisfied: transformers>=4.36.0 in /usr/local/lib/python3.10/site-packages (from vllm) (4.36.2)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/site-packages (from vllm) (5.9.8)\n",
            "Requirement already satisfied: aioprometheus[starlette] in /usr/local/lib/python3.10/site-packages (from vllm) (23.12.0)\n",
            "Requirement already satisfied: torch==2.1.2 in /usr/local/lib/python3.10/site-packages (from vllm) (2.1.2)\n",
            "Requirement already satisfied: xformers==0.0.23.post1 in /usr/local/lib/python3.10/site-packages (from vllm) (0.0.23.post1)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.10/site-packages (from vllm) (0.1.99)\n",
            "Requirement already satisfied: typing-extensions>=4.2.0 in /usr/local/lib/python3.10/site-packages (from pydantic<2,>=1->fschat) (4.9.0)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/site-packages (from torch==2.1.2->vllm) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/site-packages (from torch==2.1.2->vllm) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/site-packages (from torch==2.1.2->vllm) (11.4.5.107)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/site-packages (from torch==2.1.2->vllm) (3.13.1)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/site-packages (from torch==2.1.2->vllm) (2.1.0)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/site-packages (from torch==2.1.2->vllm) (8.9.2.26)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/site-packages (from torch==2.1.2->vllm) (2023.12.2)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/site-packages (from torch==2.1.2->vllm) (12.1.3.1)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/site-packages (from torch==2.1.2->vllm) (1.12)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/site-packages (from torch==2.1.2->vllm) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/site-packages (from torch==2.1.2->vllm) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/site-packages (from torch==2.1.2->vllm) (12.1.0.106)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/site-packages (from torch==2.1.2->vllm) (3.1.3)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/site-packages (from torch==2.1.2->vllm) (12.1.105)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/site-packages (from torch==2.1.2->vllm) (3.2.1)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/site-packages (from torch==2.1.2->vllm) (12.1.105)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.18.1 in /usr/local/lib/python3.10/site-packages (from torch==2.1.2->vllm) (2.18.1)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch==2.1.2->vllm) (12.3.101)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.10/site-packages (from openai) (1.9.0)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/site-packages (from openai) (4.65.0)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/site-packages (from openai) (4.2.0)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/site-packages (from openai) (1.3.0)\n",
            "Requirement already satisfied: et-xmlfile in /usr/local/lib/python3.10/site-packages (from openpyxl) (1.1.0)\n",
            "Requirement already satisfied: google-api-core in /usr/local/lib/python3.10/site-packages (from google-generativeai) (2.15.0)\n",
            "Requirement already satisfied: google-ai-generativelanguage==0.4.0 in /usr/local/lib/python3.10/site-packages (from google-generativeai) (0.4.0)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.10/site-packages (from google-generativeai) (4.25.2)\n",
            "Requirement already satisfied: google-auth in /usr/local/lib/python3.10/site-packages (from google-generativeai) (2.26.2)\n",
            "Requirement already satisfied: proto-plus<2.0.0dev,>=1.22.3 in /usr/local/lib/python3.10/site-packages (from google-ai-generativelanguage==0.4.0->google-generativeai) (1.23.0)\n",
            "Requirement already satisfied: tokenizers>=0.13.0 in /usr/local/lib/python3.10/site-packages (from anthropic) (0.15.0)\n",
            "Requirement already satisfied: huggingface-hub in /usr/local/lib/python3.10/site-packages (from accelerate) (0.20.2)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/site-packages (from accelerate) (6.0.1)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/site-packages (from accelerate) (23.2)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/site-packages (from accelerate) (0.4.1)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/site-packages (from pandas) (2023.4)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/site-packages (from pandas) (2023.3.post1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/site-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: stack-data in /usr/local/lib/python3.10/site-packages (from ipython) (0.6.3)\n",
            "Requirement already satisfied: matplotlib-inline in /usr/local/lib/python3.10/site-packages (from ipython) (0.1.6)\n",
            "Requirement already satisfied: traitlets>=5 in /usr/local/lib/python3.10/site-packages (from ipython) (5.14.1)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/site-packages (from ipython) (1.2.0)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.10/site-packages (from ipython) (5.1.1)\n",
            "Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.10/site-packages (from ipython) (4.9.0)\n",
            "Requirement already satisfied: jedi>=0.16 in /usr/local/lib/python3.10/site-packages (from ipython) (0.19.1)\n",
            "Requirement already satisfied: pygments>=2.4.0 in /usr/local/lib/python3.10/site-packages (from ipython) (2.17.2)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/site-packages (from anyio<5,>=3.5.0->openai) (3.4)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/site-packages (from httpx->fschat) (1.0.2)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/site-packages (from httpx->fschat) (2022.12.7)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/site-packages (from httpcore==1.*->httpx->fschat) (0.14.0)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.3 in /usr/local/lib/python3.10/site-packages (from jedi>=0.16->ipython) (0.8.3)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.10/site-packages (from pexpect>4.3->ipython) (0.7.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.10/site-packages (from prompt-toolkit>=3.0.0->fschat) (0.2.13)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
            "Requirement already satisfied: aiosignal in /usr/local/lib/python3.10/site-packages (from ray>=2.5.1->vllm) (1.3.1)\n",
            "Requirement already satisfied: msgpack<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/site-packages (from ray>=2.5.1->vllm) (1.0.7)\n",
            "Requirement already satisfied: click>=7.0 in /usr/local/lib/python3.10/site-packages (from ray>=2.5.1->vllm) (8.1.7)\n",
            "Requirement already satisfied: jsonschema in /usr/local/lib/python3.10/site-packages (from ray>=2.5.1->vllm) (4.21.1)\n",
            "Requirement already satisfied: frozenlist in /usr/local/lib/python3.10/site-packages (from ray>=2.5.1->vllm) (1.4.1)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/site-packages (from rich>=10.0.0->fschat) (3.0.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/site-packages (from transformers>=4.36.0->vllm) (2023.12.25)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/site-packages (from aiohttp->fschat) (4.0.3)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/site-packages (from aiohttp->fschat) (23.2.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/site-packages (from aiohttp->fschat) (1.9.4)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/site-packages (from aiohttp->fschat) (6.0.4)\n",
            "Requirement already satisfied: orjson in /usr/local/lib/python3.10/site-packages (from aioprometheus[starlette]->vllm) (3.9.12)\n",
            "Requirement already satisfied: quantile-python>=1.1 in /usr/local/lib/python3.10/site-packages (from aioprometheus[starlette]->vllm) (1.1)\n",
            "Requirement already satisfied: starlette>=0.14.2 in /usr/local/lib/python3.10/site-packages (from aioprometheus[starlette]->vllm) (0.35.1)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0.dev0,>=1.56.2 in /usr/local/lib/python3.10/site-packages (from google-api-core->google-generativeai) (1.62.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/site-packages (from google-auth->google-generativeai) (4.9)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/site-packages (from google-auth->google-generativeai) (0.3.0)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/site-packages (from google-auth->google-generativeai) (5.3.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/site-packages (from requests->fschat) (3.1.0)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/site-packages (from requests->fschat) (1.26.15)\n",
            "Requirement already satisfied: wavedrom in /usr/local/lib/python3.10/site-packages (from markdown2[all]->fschat) (2.0.3.post3)\n",
            "Requirement already satisfied: pure-eval in /usr/local/lib/python3.10/site-packages (from stack-data->ipython) (0.2.2)\n",
            "Requirement already satisfied: asttokens>=2.1.0 in /usr/local/lib/python3.10/site-packages (from stack-data->ipython) (2.4.1)\n",
            "Requirement already satisfied: executing>=1.2.0 in /usr/local/lib/python3.10/site-packages (from stack-data->ipython) (2.0.1)\n",
            "Requirement already satisfied: watchfiles>=0.13 in /usr/local/lib/python3.10/site-packages (from uvicorn->fschat) (0.21.0)\n",
            "Requirement already satisfied: uvloop!=0.15.0,!=0.15.1,>=0.14.0 in /usr/local/lib/python3.10/site-packages (from uvicorn->fschat) (0.19.0)\n",
            "Requirement already satisfied: python-dotenv>=0.13 in /usr/local/lib/python3.10/site-packages (from uvicorn->fschat) (1.0.0)\n",
            "Requirement already satisfied: httptools>=0.5.0 in /usr/local/lib/python3.10/site-packages (from uvicorn->fschat) (0.6.1)\n",
            "Requirement already satisfied: websockets>=10.4 in /usr/local/lib/python3.10/site-packages (from uvicorn->fschat) (12.0)\n",
            "Requirement already satisfied: grpcio<2.0dev,>=1.33.2 in /usr/local/lib/python3.10/site-packages (from google-api-core->google-generativeai) (1.60.0)\n",
            "Requirement already satisfied: grpcio-status<2.0.dev0,>=1.33.2 in /usr/local/lib/python3.10/site-packages (from google-api-core->google-generativeai) (1.60.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/site-packages (from markdown-it-py>=2.2.0->rich>=10.0.0->fschat) (0.1.2)\n",
            "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /usr/local/lib/python3.10/site-packages (from pyasn1-modules>=0.2.1->google-auth->google-generativeai) (0.5.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/site-packages (from jinja2->torch==2.1.2->vllm) (2.1.4)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.10/site-packages (from jsonschema->ray>=2.5.1->vllm) (0.32.1)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.10/site-packages (from jsonschema->ray>=2.5.1->vllm) (2023.12.1)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.10/site-packages (from jsonschema->ray>=2.5.1->vllm) (0.17.1)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/site-packages (from sympy->torch==2.1.2->vllm) (1.3.0)\n",
            "Requirement already satisfied: svgwrite in /usr/local/lib/python3.10/site-packages (from wavedrom->markdown2[all]->fschat) (1.4.3)\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "import sys\n",
        "import shutil\n",
        "\n",
        "def in_colab():\n",
        "    return \"google.colab\" in sys.modules\n",
        "\n",
        "def has_conda():\n",
        "    return shutil.which(\"conda\") is not None\n",
        "\n",
        "def install_conda():\n",
        "    !pip install -q condacolab\n",
        "    import condacolab\n",
        "    condacolab.install()\n",
        "\n",
        "if not has_conda():\n",
        "    if in_colab():\n",
        "        install_conda()\n",
        "    else:\n",
        "        raise RuntimeError(\"\"\"\n",
        "            Conda not found, and cannot be automatically installed unless\n",
        "            in a Google Colab environment.\n",
        "        \"\"\")\n",
        "\n",
        "!conda install python==3.8 pytorch torchvision torchaudio pytorch-cuda=12.1 -c pytorch -c nvidia\n",
        "%pip install fschat vllm openai termcolor openpyxl google-generativeai anthropic accelerate chardet pandas ipython"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# kernel might be reset in the previous cell\n",
        "# thus, the function should be defined again\n",
        "def in_colab():\n",
        "    return \"google.colab\" in sys.modules\n",
        "\n",
        "if in_colab():\n",
        "    from google.colab import userdata\n",
        "else:\n",
        "    from os import environ\n",
        "\n",
        "    try:\n",
        "        with open(\".env\", \"r\") as env_file:\n",
        "            for line in env_file.readlines():\n",
        "                key, value = line.split(\"=\")\n",
        "                environ[key] = value\n",
        "    except FileNotFoundError:\n",
        "        print(\"Could not find a .env file...\")\n",
        "\n",
        "def env(key):\n",
        "    try:\n",
        "        if in_colab():\n",
        "            return userdata.get(key)\n",
        "        return environ[key]\n",
        "    except KeyError:\n",
        "        print(\n",
        "            f\"\"\"Could not find variable '{key}'. If you're in a Google Colab\n",
        "            document, please make sure it's included in the 'secrets',\n",
        "            otherwise, ensure that it is available as an environment variable\n",
        "            within the jupyter kernel or added in a .env file in the same place\n",
        "            as the current jupyter notebook.\n",
        "        \"\"\")"
      ],
      "metadata": {
        "id": "CbNMC8QGMMBo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Downloading and Running the Fuzzer"
      ],
      "metadata": {
        "id": "xr9n65_bcFy3"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1_TBd0atJ0vV",
        "outputId": "0d218f67-57d1-48f6-fa34-5122852b0448"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Already up to date.\n"
          ]
        }
      ],
      "source": [
        "# This solves gptfuzz needing to be executed in the folder containing the\n",
        "# `gptfuzzer` folder. Python module resolution is something else...\n",
        "import sys\n",
        "if './gptfuzz/' not in sys.path[1]:\n",
        "    sys.path.insert(1, './gptfuzz/')\n",
        "\n",
        "# fix issue where colab doesn't recognize encoding\n",
        "if in_colab():\n",
        "    import locale\n",
        "    locale.getpreferredencoding = lambda: \"UTF-8\"\n",
        "\n",
        "try:\n",
        "    import gptfuzz as gptfuzz\n",
        "    !cd gptfuzz && git pull\n",
        "except ImportError:\n",
        "    # means that the gptfuzz folder is not in the current directory\n",
        "    # so we clone it\n",
        "    !git clone \"https://github.com/cochaviz/GPTFuzz.git\" gptfuzz || cd gptfuzz && git pull\n",
        "    import gptfuzz as gptfuzz\n",
        "\n",
        "import torch\n",
        "\n",
        "# first, empty cache\n",
        "torch.cuda.empty_cache()\n",
        "torch.cuda.memory._record_memory_history()\n",
        "\n",
        "class FuzzerArgs():\n",
        "    # the default model is gated, meaning you need permission to access it\n",
        "    # target_model =  \"meta-llama/Llama-2-7b-chat-hf\"\n",
        "    # target_model =  \"TinyLlama/TinyLlama-1.1B-Chat-v1.0\"\n",
        "    target_model = \"ahxt/LiteLlama-460M-1T\"\n",
        "    target_args = {}\n",
        "    predictor_args = {}\n",
        "    model_path = \"gpt-4\"\n",
        "    seed_path = \"gptfuzz/datasets/prompts/GPTFuzzer.csv\"\n",
        "    openai_key = env(\"OPENAIKEY\")\n",
        "    energy = 1\n",
        "    max_jailbreak = 10\n",
        "    max_query = 1000\n",
        "\n",
        "def run_fuzzer_with_args(args=FuzzerArgs()):\n",
        "    try:\n",
        "        gptfuzz.main(args)\n",
        "    except torch.cuda.OutOfMemoryError:\n",
        "        print(\"Process crashed due to lack of memory resources...\")\n",
        "        torch.cuda.memory._dump_snapshot(\"gpu_usage.pickle\")\n",
        "    finally:\n",
        "        torch.cuda.empty_cache()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "run_fuzzer_with_args()"
      ],
      "metadata": {
        "id": "XbYZ2Q2NnghU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-ODvPdOtJ0vX"
      },
      "source": [
        "\n",
        "So after a bunch of problems with my local machine regarding hardware, drivers,\n",
        "etc., I'm resorting to Google Colab for running my code (at least, the more\n",
        "intense stuff). There seems to be a package that I can use to work in Colab\n",
        "while still working in VS Code so let's give that a go."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "It works! At least, the fuzzing finishes. The single jailbreaking result I did not seem very promising, but at least it's a start. Now I can determine the specifics of the experiment and perform it! Okay, trying to run a larger (number) of experiments through upping the max jailbreak count crashes the thing because it runs out of system RAM. I have 50 GB available so that shouldn't happen. The RAM usage grows very linearly, so I expect this has to do with the number of iterations there currently are. I suspect there is some sort of history not being disposed of properly, but where that exactly is I don't know. I guess we have to enter the world of _Memory Profiling_"
      ],
      "metadata": {
        "id": "u-M4qtigwXF1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Detour: Memory Pofiling\n",
        "\n",
        "Now we have to find the root cause of this particular issue: why does the memory usage increase linearly over the fuzzing time? Honestly, I don't know... Yet! Given the large number of dependencies, I don't want to spend ages manually searching and commenting out stuff to determine what's using lots of RAM and what isn't. Therefore, I'll look at _Memory Profiling_."
      ],
      "metadata": {
        "id": "eZR1gqFU0kV2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "First, I tried a package called `memory_profiler` (very descriptive) and it works well, but is really meant to be executed from the terminal and doesn't interact nicely with notebooks. A package called `scalene` seems to be more appropriate for my particular case."
      ],
      "metadata": {
        "id": "36SLxYU7dGkr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%pip install scalene typer"
      ],
      "metadata": {
        "id": "WdjWEdDc3f89",
        "outputId": "fc5de2c6-cea2-4840-807d-af7204293a76",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: scalene in /usr/local/lib/python3.10/dist-packages (1.5.33.1)\n",
            "Requirement already satisfied: typer in /usr/local/lib/python3.10/dist-packages (0.9.0)\n",
            "Requirement already satisfied: wheel>=0.36.1 in /usr/local/lib/python3.10/dist-packages (from scalene) (0.42.0)\n",
            "Requirement already satisfied: rich>=10.7.0 in /usr/local/lib/python3.10/dist-packages (from scalene) (13.7.0)\n",
            "Requirement already satisfied: cloudpickle>=2.2.1 in /usr/local/lib/python3.10/dist-packages (from scalene) (2.2.1)\n",
            "Requirement already satisfied: pynvml<11.5,>=11.0.0 in /usr/local/lib/python3.10/dist-packages (from scalene) (11.4.1)\n",
            "Requirement already satisfied: Jinja2>=3.0.3 in /usr/local/lib/python3.10/dist-packages (from scalene) (3.1.3)\n",
            "Requirement already satisfied: psutil>=5.9.2 in /usr/local/lib/python3.10/dist-packages (from scalene) (5.9.5)\n",
            "Requirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.10/dist-packages (from typer) (8.1.7)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from typer) (4.5.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from Jinja2>=3.0.3->scalene) (2.1.3)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.7.0->scalene) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.7.0->scalene) (2.16.1)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich>=10.7.0->scalene) (0.1.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python scalene_notebook.py --scalene_args \"--html --profile_all\" --cells 15,-3  messing_around.ipynb"
      ],
      "metadata": {
        "id": "aIfThsIiddzl",
        "outputId": "e46a9840-b79b-4840-87bd-b7c67e16fb78",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/content/scalene_notebook.py\", line 33, in <module>\n",
            "    @command\n",
            "NameError: name 'command' is not defined\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FMlVGJ9XJ0vr"
      },
      "source": [
        "## Working with Red-Teaming"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "T4"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}