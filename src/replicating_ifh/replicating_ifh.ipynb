{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Intrinsic Few-Shot Hardness of Jailbreaking Datasets\n",
    "\n",
    "In this notebook, I'll be attempting to replicate the results presented in the\n",
    "paper _On Measuring the Intrinsic Few-Shot Hardness of Datasets_, specifically\n",
    "to determine whether the use of a _jailbreaking_ dataset produces results that\n",
    "are in line with their own databases. The authors of the paper collect several\n",
    "tasks from widely used datasets that, in their view, particularly reflect\n",
    "few-shot type tasks. Since we argue that jailbreaking is a few-shot learning\n",
    "task, we would expect similar results.\n",
    "\n",
    "Since their results are based on the correlation of method-specific few-shot\n",
    "hardness between different tasks, we need more tasks to determine whether our\n",
    "results are in line with theirs. Therefore, we will identify various methods of\n",
    "jailbreaking, construct a database on those and investigate the degree of their\n",
    "correlation with the rest of the results. ==One method of determining whether\n",
    "this (or any other) point is an outlier is the Z-score, but I'll have to\n",
    "investigate different methods.=="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "# conda is required by default because we\n",
    "# can avoid clashing packages. Please use\n",
    "# a new environment for this project with\n",
    "# python 3.8.\n",
    "assert os.environ[\"CONDA_DEFAULT_ENV\"] == \"ifh\"\n",
    "assert sys.version_info[:2] == (3, 8)\n",
    "\n",
    "rng_seed = 42"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reconstructing the Databases\n",
    "\n",
    "First, we reconstruct the databases as described in the paper which are referred\n",
    "to FS-GLUE and FS-NLI. For starters, we will consider the FS-GLUE dataset, as\n",
    "this only concerns a subset of the GLUE and SuperGLUE datasets. These are:\n",
    "\n",
    "- CoLA (Warstadt et al., 2018)\n",
    "- MRPC (Dolan and Brockett, 2005)\n",
    "- QQP (Wang et al., 2017)\n",
    "- MNLI (Williams et al., 2018)\n",
    "- QNLI (Rajpurkar et al., 2016)\n",
    "- RTE (Dagan et al., 2010)\n",
    "- SST-2 (Socher et al., 2013)\n",
    "\n",
    "and \n",
    "\n",
    "- BoolQ (Clark et al., 2019)\n",
    "- CB (de Marneffe et al., 2019)\n",
    "- COPA (Roemmele et al., 2011), and WiC\n",
    "\n",
    "for GLUE and SuperGLUE respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " ________________________________________ \n",
      "/ There is a certain frame of mind to    \\\n",
      "| which a cemetery is, if not an         |\n",
      "| antidote, at least an alleviation. If  |\n",
      "| you are in a fit of the blues, go      |\n",
      "| nowhere else.                          |\n",
      "|                                        |\n",
      "\\ -- Robert Louis Stevenson: Immortelles /\n",
      " ---------------------------------------- \n",
      "        \\   ^__^\n",
      "         \\  (oo)\\_______\n",
      "            (__)\\       )\\/\\\n",
      "                ||----w |\n",
      "                ||     ||\n",
      "Requirement already satisfied: transformers in /home/zohar/.conda/envs/ifh/lib/python3.8/site-packages (4.37.1)\n",
      "Requirement already satisfied: datasets in /home/zohar/.conda/envs/ifh/lib/python3.8/site-packages (2.16.1)\n",
      "Collecting torch\n",
      "  Downloading torch-2.1.2-cp38-cp38-manylinux1_x86_64.whl.metadata (25 kB)\n",
      "Requirement already satisfied: filelock in /home/zohar/.conda/envs/ifh/lib/python3.8/site-packages (from transformers) (3.13.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.19.3 in /home/zohar/.conda/envs/ifh/lib/python3.8/site-packages (from transformers) (0.20.3)\n",
      "Requirement already satisfied: numpy>=1.17 in /home/zohar/.conda/envs/ifh/lib/python3.8/site-packages (from transformers) (1.24.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/zohar/.conda/envs/ifh/lib/python3.8/site-packages (from transformers) (23.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /home/zohar/.conda/envs/ifh/lib/python3.8/site-packages (from transformers) (6.0.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /home/zohar/.conda/envs/ifh/lib/python3.8/site-packages (from transformers) (2023.12.25)\n",
      "Requirement already satisfied: requests in /home/zohar/.conda/envs/ifh/lib/python3.8/site-packages (from transformers) (2.31.0)\n",
      "Requirement already satisfied: tokenizers<0.19,>=0.14 in /home/zohar/.conda/envs/ifh/lib/python3.8/site-packages (from transformers) (0.15.1)\n",
      "Requirement already satisfied: safetensors>=0.3.1 in /home/zohar/.conda/envs/ifh/lib/python3.8/site-packages (from transformers) (0.4.2)\n",
      "Requirement already satisfied: tqdm>=4.27 in /home/zohar/.conda/envs/ifh/lib/python3.8/site-packages (from transformers) (4.66.1)\n",
      "Requirement already satisfied: pyarrow>=8.0.0 in /home/zohar/.conda/envs/ifh/lib/python3.8/site-packages (from datasets) (15.0.0)\n",
      "Requirement already satisfied: pyarrow-hotfix in /home/zohar/.conda/envs/ifh/lib/python3.8/site-packages (from datasets) (0.6)\n",
      "Requirement already satisfied: dill<0.3.8,>=0.3.0 in /home/zohar/.conda/envs/ifh/lib/python3.8/site-packages (from datasets) (0.3.7)\n",
      "Requirement already satisfied: pandas in /home/zohar/.conda/envs/ifh/lib/python3.8/site-packages (from datasets) (2.0.3)\n",
      "Requirement already satisfied: xxhash in /home/zohar/.conda/envs/ifh/lib/python3.8/site-packages (from datasets) (3.4.1)\n",
      "Requirement already satisfied: multiprocess in /home/zohar/.conda/envs/ifh/lib/python3.8/site-packages (from datasets) (0.70.15)\n",
      "Requirement already satisfied: fsspec<=2023.10.0,>=2023.1.0 in /home/zohar/.conda/envs/ifh/lib/python3.8/site-packages (from fsspec[http]<=2023.10.0,>=2023.1.0->datasets) (2023.10.0)\n",
      "Requirement already satisfied: aiohttp in /home/zohar/.conda/envs/ifh/lib/python3.8/site-packages (from datasets) (3.9.1)\n",
      "Requirement already satisfied: typing-extensions in /home/zohar/.conda/envs/ifh/lib/python3.8/site-packages (from torch) (4.9.0)\n",
      "Collecting sympy (from torch)\n",
      "  Downloading sympy-1.12-py3-none-any.whl (5.7 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.7/5.7 MB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting networkx (from torch)\n",
      "  Downloading networkx-3.1-py3-none-any.whl (2.1 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting jinja2 (from torch)\n",
      "  Downloading Jinja2-3.1.3-py3-none-any.whl.metadata (3.3 kB)\n",
      "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch)\n",
      "  Downloading nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.7/23.7 MB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-cuda-runtime-cu12==12.1.105 (from torch)\n",
      "  Downloading nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m823.6/823.6 kB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-cuda-cupti-cu12==12.1.105 (from torch)\n",
      "  Downloading nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.1/14.1 MB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-cudnn-cu12==8.9.2.26 (from torch)\n",
      "  Downloading nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cublas-cu12==12.1.3.1 (from torch)\n",
      "  Downloading nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m410.6/410.6 MB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:02\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-cufft-cu12==11.0.2.54 (from torch)\n",
      "  Downloading nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m121.6/121.6 MB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-curand-cu12==10.3.2.106 (from torch)\n",
      "  Downloading nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.5/56.5 MB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-cusolver-cu12==11.4.5.107 (from torch)\n",
      "  Downloading nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m124.2/124.2 MB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-cusparse-cu12==12.1.0.106 (from torch)\n",
      "  Downloading nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m196.0/196.0 MB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-nccl-cu12==2.18.1 (from torch)\n",
      "  Downloading nvidia_nccl_cu12-2.18.1-py3-none-manylinux1_x86_64.whl (209.8 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m209.8/209.8 MB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-nvtx-cu12==12.1.105 (from torch)\n",
      "  Downloading nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.1/99.1 kB\u001b[0m \u001b[31m16.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting triton==2.1.0 (from torch)\n",
      "  Downloading triton-2.1.0-0-cp38-cp38-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.3 kB)\n",
      "Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch)\n",
      "  Downloading nvidia_nvjitlink_cu12-12.3.101-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /home/zohar/.conda/envs/ifh/lib/python3.8/site-packages (from aiohttp->datasets) (23.2.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /home/zohar/.conda/envs/ifh/lib/python3.8/site-packages (from aiohttp->datasets) (6.0.4)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /home/zohar/.conda/envs/ifh/lib/python3.8/site-packages (from aiohttp->datasets) (1.9.4)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /home/zohar/.conda/envs/ifh/lib/python3.8/site-packages (from aiohttp->datasets) (1.4.1)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /home/zohar/.conda/envs/ifh/lib/python3.8/site-packages (from aiohttp->datasets) (1.3.1)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0 in /home/zohar/.conda/envs/ifh/lib/python3.8/site-packages (from aiohttp->datasets) (4.0.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/zohar/.conda/envs/ifh/lib/python3.8/site-packages (from requests->transformers) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/zohar/.conda/envs/ifh/lib/python3.8/site-packages (from requests->transformers) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/zohar/.conda/envs/ifh/lib/python3.8/site-packages (from requests->transformers) (2.1.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/zohar/.conda/envs/ifh/lib/python3.8/site-packages (from requests->transformers) (2023.11.17)\n",
      "Collecting MarkupSafe>=2.0 (from jinja2->torch)\n",
      "  Downloading MarkupSafe-2.1.4-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.0 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /home/zohar/.conda/envs/ifh/lib/python3.8/site-packages (from pandas->datasets) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/zohar/.conda/envs/ifh/lib/python3.8/site-packages (from pandas->datasets) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /home/zohar/.conda/envs/ifh/lib/python3.8/site-packages (from pandas->datasets) (2023.4)\n",
      "Collecting mpmath>=0.19 (from sympy->torch)\n",
      "  Downloading mpmath-1.3.0-py3-none-any.whl (536 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m536.2/536.2 kB\u001b[0m \u001b[31m10.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: six>=1.5 in /home/zohar/.conda/envs/ifh/lib/python3.8/site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n",
      "Downloading torch-2.1.2-cp38-cp38-manylinux1_x86_64.whl (670.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m670.2/670.2 MB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:02\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m731.7/731.7 MB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:03\u001b[0m\n",
      "\u001b[?25hDownloading triton-2.1.0-0-cp38-cp38-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (89.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m89.2/89.2 MB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading Jinja2-3.1.3-py3-none-any.whl (133 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m133.2/133.2 kB\u001b[0m \u001b[31m14.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading MarkupSafe-2.1.4-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (26 kB)\n",
      "Downloading nvidia_nvjitlink_cu12-12.3.101-py3-none-manylinux1_x86_64.whl (20.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m20.5/20.5 MB\u001b[0m \u001b[31m8.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: mpmath, triton, sympy, nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, networkx, MarkupSafe, nvidia-cusparse-cu12, nvidia-cudnn-cu12, jinja2, nvidia-cusolver-cu12, torch\n",
      "Successfully installed MarkupSafe-2.1.4 jinja2-3.1.3 mpmath-1.3.0 networkx-3.1 nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.18.1 nvidia-nvjitlink-cu12-12.3.101 nvidia-nvtx-cu12-12.1.105 sympy-1.12 torch-2.1.2 triton-2.1.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install transformers datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded FS-GLUE tasks:  ['boolq', 'cb', 'copa', 'wic', 'cola', 'mrpc', 'qqp', 'mnli', 'qnli', 'rte', 'sst2']\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "glue_task_names = [ \"cola\", \"mrpc\", \"qqp\", \"mnli\", \"qnli\", \"rte\" , \"sst2\" ]\n",
    "glue_tasks = { task_name : load_dataset(\"glue\", task_name) for task_name in glue_task_names }\n",
    "\n",
    "sglue_task_names = [ \"boolq\", \"cb\", \"copa\" , \"wic\" ]\n",
    "sglue_tasks = { task_name : load_dataset(\"super_glue\", task_name) for task_name in sglue_task_names }\n",
    "\n",
    "sglue_tasks.update(glue_tasks)\n",
    "fs_glue = sglue_tasks\n",
    "\n",
    "print(\"Loaded FS-GLUE tasks: \", list(fs_glue.keys()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reconstructing the Fine-Tuning Methods\n",
    "\n",
    "Secondly, we will set up an environment in which we can easily choose\n",
    "fine-tuning methods, models, and the dataset on which we would like to perform\n",
    "that fine-tuning. In the paper, they consider three different categories of\n",
    "fine-tuning, each with their respective fine-tuning methods:\n",
    "\n",
    "- _Prompt-based_:\n",
    "  - LMBFF\n",
    "  - AdaPET\n",
    "  - Null Prompts\n",
    "  - Prompt-Bitfit\n",
    "- _Light-weight_:\n",
    "  - Prefix Tuning\n",
    "  - Compacter "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LMBFF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " ____________________________________ \n",
      "/ Q: What does a WASP Mom make for   \\\n",
      "| dinner? A: A crisp salad, a hearty |\n",
      "| soup, a lovely entree, followed by |\n",
      "|                                    |\n",
      "\\ a delicious dessert.               /\n",
      " ------------------------------------ \n",
      "        \\   ^__^\n",
      "         \\  (oo)\\_______\n",
      "            (__)\\       )\\/\\\n",
      "                ||----w |\n",
      "                ||     ||\n",
      "fatal: destination path 'LM_BFF' already exists and is not an empty directory.\n",
      "git@github.com: Permission denied (publickey).\n",
      "fatal: Could not read from remote repository.\n",
      "\n",
      "Please make sure you have the correct access rights\n",
      "and the repository exists.\n",
      "lmbff                    /home/zohar/.conda/envs/lmbff\n",
      "Conda environment lmbff already exists\n",
      "Requirement already satisfied: certifi==2020.12.5 in /home/zohar/.conda/envs/lmbff/lib/python3.6/site-packages (from -r requirements.txt (line 1)) (2020.12.5)\n",
      "Requirement already satisfied: chardet==4.0.0 in /home/zohar/.conda/envs/lmbff/lib/python3.6/site-packages (from -r requirements.txt (line 2)) (4.0.0)\n",
      "Requirement already satisfied: click==7.1.2 in /home/zohar/.conda/envs/lmbff/lib/python3.6/site-packages (from -r requirements.txt (line 3)) (7.1.2)\n",
      "Requirement already satisfied: dataclasses==0.8 in /home/zohar/.conda/envs/lmbff/lib/python3.6/site-packages (from -r requirements.txt (line 4)) (0.8)\n",
      "Requirement already satisfied: filelock==3.0.12 in /home/zohar/.conda/envs/lmbff/lib/python3.6/site-packages (from -r requirements.txt (line 5)) (3.0.12)\n",
      "Requirement already satisfied: flake8==3.8.4 in /home/zohar/.conda/envs/lmbff/lib/python3.6/site-packages (from -r requirements.txt (line 6)) (3.8.4)\n",
      "Requirement already satisfied: future==0.18.2 in /home/zohar/.conda/envs/lmbff/lib/python3.6/site-packages (from -r requirements.txt (line 7)) (0.18.2)\n",
      "Requirement already satisfied: idna==2.10 in /home/zohar/.conda/envs/lmbff/lib/python3.6/site-packages (from -r requirements.txt (line 8)) (2.10)\n",
      "Requirement already satisfied: importlib-metadata==3.3.0 in /home/zohar/.conda/envs/lmbff/lib/python3.6/site-packages (from -r requirements.txt (line 9)) (3.3.0)\n",
      "Requirement already satisfied: joblib==1.0.0 in /home/zohar/.conda/envs/lmbff/lib/python3.6/site-packages (from -r requirements.txt (line 10)) (1.0.0)\n",
      "Requirement already satisfied: mccabe==0.6.1 in /home/zohar/.conda/envs/lmbff/lib/python3.6/site-packages (from -r requirements.txt (line 11)) (0.6.1)\n",
      "Requirement already satisfied: nltk>=3.6.4 in /home/zohar/.conda/envs/lmbff/lib/python3.6/site-packages (from -r requirements.txt (line 12)) (3.6.7)\n",
      "Requirement already satisfied: numpy==1.19.4 in /home/zohar/.conda/envs/lmbff/lib/python3.6/site-packages (from -r requirements.txt (line 13)) (1.19.4)\n",
      "Requirement already satisfied: packaging==20.8 in /home/zohar/.conda/envs/lmbff/lib/python3.6/site-packages (from -r requirements.txt (line 14)) (20.8)\n",
      "Requirement already satisfied: pandas==1.1.5 in /home/zohar/.conda/envs/lmbff/lib/python3.6/site-packages (from -r requirements.txt (line 15)) (1.1.5)\n",
      "Requirement already satisfied: protobuf==3.14.0 in /home/zohar/.conda/envs/lmbff/lib/python3.6/site-packages (from -r requirements.txt (line 16)) (3.14.0)\n",
      "Requirement already satisfied: pycodestyle==2.6.0 in /home/zohar/.conda/envs/lmbff/lib/python3.6/site-packages (from -r requirements.txt (line 17)) (2.6.0)\n",
      "Requirement already satisfied: pyflakes==2.2.0 in /home/zohar/.conda/envs/lmbff/lib/python3.6/site-packages (from -r requirements.txt (line 18)) (2.2.0)\n",
      "Requirement already satisfied: pyparsing==2.4.7 in /home/zohar/.conda/envs/lmbff/lib/python3.6/site-packages (from -r requirements.txt (line 19)) (2.4.7)\n",
      "Requirement already satisfied: python-dateutil==2.8.1 in /home/zohar/.conda/envs/lmbff/lib/python3.6/site-packages (from -r requirements.txt (line 20)) (2.8.1)\n",
      "Requirement already satisfied: pytz==2020.5 in /home/zohar/.conda/envs/lmbff/lib/python3.6/site-packages (from -r requirements.txt (line 21)) (2020.5)\n",
      "Requirement already satisfied: requests==2.25.1 in /home/zohar/.conda/envs/lmbff/lib/python3.6/site-packages (from -r requirements.txt (line 22)) (2.25.1)\n",
      "Requirement already satisfied: sacremoses==0.0.43 in /home/zohar/.conda/envs/lmbff/lib/python3.6/site-packages (from -r requirements.txt (line 23)) (0.0.43)\n",
      "Requirement already satisfied: scikit-learn==0.24.0 in /home/zohar/.conda/envs/lmbff/lib/python3.6/site-packages (from -r requirements.txt (line 24)) (0.24.0)\n",
      "Requirement already satisfied: scipy==1.5.4 in /home/zohar/.conda/envs/lmbff/lib/python3.6/site-packages (from -r requirements.txt (line 25)) (1.5.4)\n",
      "Requirement already satisfied: sentence-transformers==0.4.0 in /home/zohar/.conda/envs/lmbff/lib/python3.6/site-packages (from -r requirements.txt (line 26)) (0.4.0)\n",
      "Requirement already satisfied: sentencepiece==0.1.94 in /home/zohar/.conda/envs/lmbff/lib/python3.6/site-packages (from -r requirements.txt (line 27)) (0.1.94)\n",
      "Requirement already satisfied: six==1.15.0 in /home/zohar/.conda/envs/lmbff/lib/python3.6/site-packages (from -r requirements.txt (line 28)) (1.15.0)\n",
      "Requirement already satisfied: threadpoolctl==2.1.0 in /home/zohar/.conda/envs/lmbff/lib/python3.6/site-packages (from -r requirements.txt (line 29)) (2.1.0)\n",
      "Requirement already satisfied: tokenizers==0.9.2 in /home/zohar/.conda/envs/lmbff/lib/python3.6/site-packages (from -r requirements.txt (line 30)) (0.9.2)\n",
      "Requirement already satisfied: torch==1.6.0 in /home/zohar/.conda/envs/lmbff/lib/python3.6/site-packages (from -r requirements.txt (line 31)) (1.6.0)\n",
      "Requirement already satisfied: tqdm==4.48.2 in /home/zohar/.conda/envs/lmbff/lib/python3.6/site-packages (from -r requirements.txt (line 32)) (4.48.2)\n",
      "Requirement already satisfied: transformers==3.4.0 in /home/zohar/.conda/envs/lmbff/lib/python3.6/site-packages (from -r requirements.txt (line 33)) (3.4.0)\n",
      "Requirement already satisfied: typing-extensions==3.7.4.3 in /home/zohar/.conda/envs/lmbff/lib/python3.6/site-packages (from -r requirements.txt (line 34)) (3.7.4.3)\n",
      "Requirement already satisfied: urllib3>=1.26.4 in /home/zohar/.conda/envs/lmbff/lib/python3.6/site-packages (from -r requirements.txt (line 35)) (1.26.18)\n",
      "Requirement already satisfied: zipp==3.4.0 in /home/zohar/.conda/envs/lmbff/lib/python3.6/site-packages (from -r requirements.txt (line 36)) (3.4.0)\n",
      "Requirement already satisfied: regex in /home/zohar/.conda/envs/lmbff/lib/python3.6/site-packages (from sacremoses==0.0.43->-r requirements.txt (line 23)) (2023.8.8)\n",
      "\n",
      "/home/zohar/Documents/Study/msc/y2/mep/src/replicating_ifh/LM_BFF\n",
      "K = 16\n",
      "Seed = 100\n",
      "| Task = SST-2\n",
      "| Task = sst-5\n",
      "| Task = mr\n",
      "| Task = cr\n",
      "| Task = mpqa\n",
      "| Task = subj\n",
      "| Task = trec\n",
      "| Task = CoLA\n",
      "| Task = MRPC\n",
      "| Task = QQP\n",
      "| Task = STS-B\n",
      "| Task = MNLI\n",
      "| Task = SNLI\n",
      "| Task = QNLI\n",
      "| Task = RTE\n",
      "Seed = 13\n",
      "| Task = SST-2\n",
      "| Task = sst-5\n",
      "| Task = mr\n",
      "| Task = cr\n",
      "| Task = mpqa\n",
      "| Task = subj\n",
      "| Task = trec\n",
      "| Task = CoLA\n",
      "| Task = MRPC\n",
      "| Task = QQP\n",
      "| Task = STS-B\n",
      "| Task = MNLI\n",
      "| Task = SNLI\n",
      "| Task = QNLI\n",
      "| Task = RTE\n",
      "Seed = 21\n",
      "| Task = SST-2\n",
      "| Task = sst-5\n",
      "| Task = mr\n",
      "| Task = cr\n",
      "| Task = mpqa\n",
      "| Task = subj\n",
      "| Task = trec\n",
      "| Task = CoLA\n",
      "| Task = MRPC\n",
      "| Task = QQP\n",
      "| Task = STS-B\n",
      "| Task = MNLI\n",
      "| Task = SNLI\n",
      "| Task = QNLI\n",
      "| Task = RTE\n",
      "Seed = 42\n",
      "| Task = SST-2\n",
      "| Task = sst-5\n",
      "| Task = mr\n",
      "| Task = cr\n",
      "| Task = mpqa\n",
      "| Task = subj\n",
      "| Task = trec\n",
      "| Task = CoLA\n",
      "| Task = MRPC\n",
      "| Task = QQP\n",
      "| Task = STS-B\n",
      "| Task = MNLI\n",
      "| Task = SNLI\n",
      "| Task = QNLI\n",
      "| Task = RTE\n",
      "Seed = 87\n",
      "| Task = SST-2\n",
      "| Task = sst-5\n",
      "| Task = mr\n",
      "| Task = cr\n",
      "| Task = mpqa\n",
      "| Task = subj\n",
      "| Task = trec\n",
      "| Task = CoLA\n",
      "| Task = MRPC\n",
      "| Task = QQP\n",
      "| Task = STS-B\n",
      "| Task = MNLI\n",
      "| Task = SNLI\n",
      "| Task = QNLI\n",
      "| Task = RTE\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!./setup_lmbff.sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zohar/.conda/envs/lmbff/lib/python3.6/site-packages/transformers/training_args.py:339: FutureWarning: The `evaluate_during_training` argument is deprecated in favor of `evaluation_strategy` (which has more options)\n",
      "  FutureWarning,\n",
      "01/26/2024 16:05:53 - WARNING - __main__ -   Process rank: -1, device: cpu, n_gpu: 0, distributed training: False, 16-bits training: False\n",
      "01/26/2024 16:05:53 - INFO - __main__ -   Training/evaluation parameters DynamicTrainingArguments(output_dir='result/tmp', overwrite_output_dir=True, do_train=True, do_eval=True, do_predict=True, evaluate_during_training=True, evaluation_strategy=<EvaluationStrategy.STEPS: 'steps'>, prediction_loss_only=False, per_device_train_batch_size=2, per_device_eval_batch_size=8, per_gpu_train_batch_size=None, per_gpu_eval_batch_size=None, gradient_accumulation_steps=1, eval_accumulation_steps=None, learning_rate=1e-05, weight_decay=0.0, adam_beta1=0.9, adam_beta2=0.999, adam_epsilon=1e-08, max_grad_norm=1.0, num_train_epochs=0.0, max_steps=1000, warmup_steps=0, logging_dir='runs/Jan26_16-05-53_bunker', logging_first_step=False, logging_steps=500, save_steps=500, save_total_limit=None, no_cuda=False, seed=42, fp16=False, fp16_opt_level='O1', local_rank=-1, tpu_num_cores=None, tpu_metrics_debug=False, debug=False, dataloader_drop_last=False, eval_steps=100, dataloader_num_workers=0, past_index=-1, run_name='result/tmp', disable_tqdm=False, remove_unused_columns=True, label_names=None, load_best_model_at_end=False, metric_for_best_model=None, greater_is_better=None, array_id=-1, model_id=-1, save_logit=False, save_logit_dir=None, fix_layers=0, save_at_last=False, no_train=False, no_predict=False)\n",
      "01/26/2024 16:05:53 - INFO - __main__ -   Task name: sst-2, number of labels: 2, output mode: classification\n",
      "01/26/2024 16:05:55 - INFO - src.dataset -   Label 0 to word terrible (6659)\n",
      "01/26/2024 16:05:55 - INFO - src.dataset -   Label 1 to word great (2307)\n",
      "01/26/2024 16:05:55 - INFO - src.dataset -   Total num_sample for mode train: 1\n",
      "01/26/2024 16:05:55 - INFO - src.dataset -   Creating/loading examples from dataset file at data/k-shot/SST-2/16-42\n",
      "Traceback (most recent call last):\n",
      "  File \"LM_BFF/run.py\", line 628, in <module>\n",
      "    main()\n",
      "  File \"LM_BFF/run.py\", line 457, in main\n",
      "    FewShotDataset(data_args, tokenizer=tokenizer, mode=\"train\", use_demo=(\"demo\" in model_args.few_shot_type))\n",
      "  File \"/home/zohar/Documents/Study/msc/y2/mep/src/replicating_ifh/LM_BFF/src/dataset.py\", line 332, in __init__\n",
      "    with FileLock(lock_path):\n",
      "  File \"/home/zohar/.conda/envs/lmbff/lib/python3.6/site-packages/filelock.py\", line 323, in __enter__\n",
      "    self.acquire()\n",
      "  File \"/home/zohar/.conda/envs/lmbff/lib/python3.6/site-packages/filelock.py\", line 271, in acquire\n",
      "    self._acquire()\n",
      "  File \"/home/zohar/.conda/envs/lmbff/lib/python3.6/site-packages/filelock.py\", line 384, in _acquire\n",
      "    fd = os.open(self._lock_file, open_mode)\n",
      "FileNotFoundError: [Errno 2] No such file or directory: 'data/k-shot/SST-2/16-42/cached_train_BertTokenizer_128_sst-2.lock'\n",
      "\n",
      "ERROR conda.cli.main_run:execute(49): `conda run python LM_BFF/run.py --task_name sst-2 --data_dir data/k-shot/SST-2/16-42 --overwrite_output_dir --do_train --do_eval --do_predict --evaluate_during_training --model_name_or_path bert-base-uncased --few_shot_type prompt --num_k 64 --max_steps 1000 --eval_steps 100 --per_device_train_batch_size 2 --learning_rate 1e-5 --num_train_epochs 0 --output_dir result/tmp --seed 42 --template *cls**sent_0*_It_was*mask*.*sep+* --mapping {'0':'terrible','1':'great'} --num_sample 16` failed. (See above for error)\n"
     ]
    }
   ],
   "source": [
    "import subprocess\n",
    "\n",
    "def LMBFF(model_path, task_name):\n",
    "    if task_name == \"sst2\":\n",
    "        task_name = \"sst-2\"\n",
    "\n",
    "    subprocess.run([\"conda\", \"run\", \"-n\", \"lmbff\", \"python\", \"LM_BFF/run.py\",\n",
    "        \"--task_name\", task_name,\n",
    "        \"--data_dir\", \"data/k-shot/SST-2/16-42\",\n",
    "        \"--overwrite_output_dir\",\n",
    "        \"--do_train\",\n",
    "        \"--do_eval\",\n",
    "        \"--do_predict\",\n",
    "        \"--evaluate_during_training\",\n",
    "        \"--model_name_or_path\", model_path,\n",
    "        \"--few_shot_type\", \"prompt\",\n",
    "        \"--num_k\", \"64\", # not sure about this\n",
    "        \"--max_steps\", \"1000\",\n",
    "        \"--eval_steps\", \"100\",\n",
    "        \"--per_device_train_batch_size\", \"2\",\n",
    "        \"--learning_rate\", \"1e-5\",\n",
    "        \"--num_train_epochs\", \"0\",\n",
    "        \"--output_dir\", \"result/tmp\",\n",
    "        \"--seed\", str(rng_seed),\n",
    "        \"--template\", \"*cls**sent_0*_It_was*mask*.*sep+*\",\n",
    "        \"--mapping\", \"{'0':'terrible','1':'great'}\",\n",
    "        \"--num_sample\", \"16\",\n",
    "    ])\n",
    "\n",
    "LMBFF(\"bert-base-uncased\", \"sst2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining Spread"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
